#!/usr/bin/python
"""
Univariate_feature selection

"""
import numpy as np
import pylab as pl
from sklearn import preprocessing
from sklearn import svm
from sklearn import feature_selection
from utility_extra import mape

# Columns of data:
# 0-ID  1-Label  2-House  3-Year  4-Month  5-Temperature  6-Daylight  7-Mean EnergyProduction 8-VarianceEP
#data_train = np.loadtxt("/home/nicolas/workspace/camenergydatalab/EnergyDataSimulationChallenge/challenge1/data/training_dataset_500_nh.csv", delimiter=',')
#data_test = np.loadtxt("/home/nicolas/workspace/camenergydatalab/EnergyDataSimulationChallenge/challenge1/data/test_dataset_500_nh.csv", delimiter=',')
#x_train = data_train[:, :8]
#y_train = data_train[:, 8]
#x_test = data_test[:, :8]
#y_test = data_test[:, 8]

# 0-ID  1-Label  2-House  3-Year  4-Month  5-Temperature  6-Daylight  7-EnergyProduction
data_train = np.loadtxt("/home/nicolas/workspace/camenergydatalab/EnergyDataSimulationChallenge/challenge1/data/training_dataset_500.csv", delimiter=',', skiprows=1)
data_test = np.loadtxt("/home/nicolas/workspace/camenergydatalab/EnergyDataSimulationChallenge/challenge1/data/test_dataset_500.csv", delimiter=',', skiprows=1)
x_train = data_train[:, :7]
y_train = data_train[:, 7]
x_test = data_test[:, :7]
y_test = data_test[:, 7]


scaler = preprocessing.StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

normalizer = preprocessing.Normalizer()
x_train_norm = normalizer.fit_transform(x_train_scaled)
x_test_norm = normalizer.transform(x_test_scaled)

###############################################################################
#pl.figure(1)
#pl.clf()

X_indices = np.arange(x_train_norm.shape[-1])
###############################################################################
# Univariate feature selection with F-test for feature scoring
# We use the default selection function: the 10% most significant features
selector = feature_selection.SelectPercentile(feature_selection.f_regression, percentile=60)
selector.fit(x_train_norm, y_train)

#print "MAPE score with selector: ", mape( y_test, selector.predict(x_test_norm))
#scores = -np.log10(selector.pvalues_)
#scores /= scores.max()
#pl.bar(X_indices - .45, scores, width=.2,
#       label=r'Univariate score ($-Log(p_{value})$)', color='g')

###############################################################################
# Compare to the weights of an SVM
clf = svm.SVR(kernel='linear')
clf.fit(x_train_norm, y_train)
print "MAPE score SVR: ", mape( y_test, clf.predict(x_test_norm))

svm_weights = (clf.coef_ ** 2).sum(axis=0)
svm_weights /= svm_weights.max()

pl.bar(X_indices - .25, svm_weights, width=.2, label='SVR weight', color='r')

clf_selected = svm.SVR(kernel='linear')
clf_selected.fit(selector.transform(x_train_norm), y_train)
print "MAPE score SVR with selector: ", mape( y_test, clf_selected.predict(selector.transform(x_test_norm)))

svm_weights_selected = (clf_selected.coef_ ** 2).sum(axis=0)
svm_weights_selected /= svm_weights_selected.max()

pl.bar(X_indices[selector.get_support()] - .05, svm_weights_selected, width=.2,
       label='SVR weights after selection', color='b')


pl.title("Comparing feature selection")
pl.xlabel('Feature number')
pl.yticks(())
pl.axis('tight')
pl.legend(loc='upper right')
pl.show()
